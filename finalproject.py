# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11P2jLrEKz1fxtEivixAE4TtJJF2DUGt9

Bold = Done

Introduction: Describe the problem statement and task definition, as in the proposal. Be sure to address any feedback you received from the proposal. If you have changed your project, those changes should also be reflected here. Also include an update on your overall results and progress so far.

**Related work: This can be the same as the proposal, but be sure to address any feedback you received.**

Dataset and Evaluation: By now, you should have a dataset, and should also have a train/dev/test split of the dataset. (In some cases, you may not have enough data to create a train/dev/test split, in which case you should discuss alternatives such as cross-validation to choose hyperparameters.) Describe the dataset in detail, such as how many examples are in each split. If this is a classification dataset, report statistics like how many examples are of each class. If you created the dataset yourself (e.g., by scraping some websites), describe how you did that. Finally, describe the evaluation metrics you’ve chosen and why they are appropriate.

Methods: By now you should have tested at least two methods. At least one should be a machine learning method, and the other should be a baseline. It is also acceptable to have two different machine learning methods. Describe each method in detail here, including a step-by-step description of how your inputs are mapped to outputs. Include details such as how you create features, and what the hyperparameters are and how you chose them. It is okay if the current machine learning methods you’ve tried are not the final one you want to use.

Experiments: Describe the results when you test each of your methods. Display these results in a table or appropriate chart. Also include results of experiments you ran on the development set to select hyperparameters. Comment whether the methods perform differently, which is better, and why you think that is.

Discussion: After running your methods, you should do manual error analysis to understand what happened. Take a random sample of your development examples and study the cases that the model got wrong. Do you see any patterns? By looking at the examples, why do you think they were hard for the model? Based on your error analysis, suggest at least two concrete ways you could improve the model’s accuracy.

Conclusion: Summarize your progress so far and what you will do by the final report.

# Read Me Ig

Try to pair a comment with code section \\
Can comment in code as well \\
But summary above will probably make what we are trying to do easier to comprehend

# Points Summary

Offense:
*   Rushing/Receiving Touchdown: 6 points
*   Passing Touchdown: 4 points 
*   Passing yards: 1 points per 25 yards 
*   Rushing yards: 1 point per 10 yards 
*   Receiving yards: 1 point per 10 yards 
*   2 point Conversion: 2 points 
*   Interception: -2 points 
*   Fumble: -2 points 

Kicking:
*   PAT Made: 1 point 
*   FG Made (0-49 yards): 3 points 
*   FG Made (50+ yards): 5 points 
*   FG Missed: -1 points 

Still Deciding on whether or not to include defense/special teams

# Intial modules and tables

Basically Importing the packages/modules I think we need
"""

# Import scraping modules
from urllib.request import urlopen
from bs4 import BeautifulSoup

# Import data manipulation modules
import pandas as pd
import numpy as np
import seaborn as sns

# Import data visualization modules
import matplotlib as mpl
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.linear_model import Ridge
from sklearn.linear_model import SGDRegressor

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

"""Still working on how we are gonna make the tables \
Might need to do passing table and rushing table  \\
But we will see

Headers for table \\
Currently only for passing yards \\
I'll prob just work with passing for now to keep it simple \\
Hopefully we can then just copy and paste after but with the other variables
"""

# 2022
# Page URL
passing_2022 = 'https://www.pro-football-reference.com/years/2022/passing.htm'
rushing_2022 = 'https://www.pro-football-reference.com/years/2022/rushing.htm'
receiving_2022 = 'https://www.pro-football-reference.com/years/2022/receiving.htm'

# Open and Pass url to Beautiful Soup
html = urlopen(passing_2022)
passing_2022_stats = BeautifulSoup(html)
html = urlopen(rushing_2022)
rushing_2022_stats = BeautifulSoup(html)
html = urlopen(receiving_2022)
receiving_2022_stats = BeautifulSoup(html)

# Headers
passing_col_headers = passing_2022_stats.findAll('tr')[0]
passing_col_headers = [i.getText() for i in passing_col_headers.findAll('th')]

rushing_col_headers = rushing_2022_stats.findAll('tr')[1]
rushing_col_headers = [i.getText() for i in rushing_col_headers.findAll('th')]

receiving_col_headers = receiving_2022_stats.findAll('tr')[0]
receiving_col_headers = [i.getText() for i in receiving_col_headers.findAll('th')]

# 2021
# Page URL
passing_2021 = 'https://www.pro-football-reference.com/years/2021/passing.htm'
rushing_2021 = 'https://www.pro-football-reference.com/years/2021/rushing.htm'
receiving_2021 = 'https://www.pro-football-reference.com/years/2021/receiving.htm'

# Open and Pass url to Beautiful Soup
html = urlopen(passing_2021)
passing_2021_stats = BeautifulSoup(html)
html = urlopen(rushing_2021)
rushing_2021_stats = BeautifulSoup(html)
html = urlopen(receiving_2021)
receiving_2021_stats = BeautifulSoup(html)

# Headers
passing_col_headers2021 = passing_2021_stats.findAll('tr')[0]
passing_col_headers2021 = [i.getText() for i in passing_col_headers2021.findAll('th')]

rushing_col_headers2021 = rushing_2021_stats.findAll('tr')[1]
rushing_col_headers2021 = [i.getText() for i in rushing_col_headers2021.findAll('th')]

receiving_col_headers2021 = receiving_2021_stats.findAll('tr')[0]
receiving_col_headers2021 = [i.getText() for i in receiving_col_headers2021.findAll('th')]

# 2020
# Page URL
passing_2020 = 'https://www.pro-football-reference.com/years/2020/passing.htm'
rushing_2020 = 'https://www.pro-football-reference.com/years/2020/rushing.htm'
receiving_2020 = 'https://www.pro-football-reference.com/years/2020/receiving.htm'

# Open and Pass url to Beautiful Soup
html = urlopen(passing_2020)
passing_2020_stats = BeautifulSoup(html)
html = urlopen(rushing_2020)
rushing_2020_stats = BeautifulSoup(html)
html = urlopen(receiving_2020)
receiving_2020_stats = BeautifulSoup(html)

# Headers
passing_col_headers2020 = passing_2020_stats.findAll('tr')[0]
passing_col_headers2020 = [i.getText() for i in passing_col_headers2020.findAll('th')]

rushing_col_headers2020 = rushing_2020_stats.findAll('tr')[1]
rushing_col_headers2020 = [i.getText() for i in rushing_col_headers2020.findAll('th')]

receiving_col_headers2020 = receiving_2020_stats.findAll('tr')[0]
receiving_col_headers2020 = [i.getText() for i in receiving_col_headers2020.findAll('th')]

"""Table headers and table rows """

# Get table rows into an array
rows = passing_2022_stats.findAll('tr')[1:]

# Get stats from each row
passing_stats = []
for x in range(len(rows)):
    passing_stats.append([col.getText() for col in rows[x].findAll('td')])
    
# Get table rows into an array
rows = passing_2021_stats.findAll('tr')[1:]

# Get stats from each row
passing_stats2 = []
for x in range(len(rows)):
    passing_stats2.append([col.getText() for col in rows[x].findAll('td')])
    
# Get table rows into an array
rows = passing_2020_stats.findAll('tr')[1:]

# Get stats from each row
passing_stats3 = []
for x in range(len(rows)):
    passing_stats3.append([col.getText() for col in rows[x].findAll('td')])

# Get table rows into an array
rows = receiving_2022_stats.findAll('tr')[1:]

# Get stats from each row
receiving_stats = []
for x in range(len(rows)):
    receiving_stats.append([col.getText() for col in rows[x].findAll('td')])
    
# Get table rows into an array
rows = receiving_2021_stats.findAll('tr')[1:]

# Get stats from each row
receiving_stats2 = []
for x in range(len(rows)):
    receiving_stats2.append([col.getText() for col in rows[x].findAll('td')])
    
# Get table rows into an array
rows = receiving_2020_stats.findAll('tr')[1:]

# Get stats from each row
receiving_stats3 = []
for x in range(len(rows)):
    receiving_stats3.append([col.getText() for col in rows[x].findAll('td')])

# Get table rows into an array
rows = rushing_2022_stats.findAll('tr')[2:]

# Get stats from each row
rushing_stats = []
for x in range(len(rows)):
    rushing_stats.append([col.getText() for col in rows[x].findAll('td')])
    
# Get table rows into an array
rows = rushing_2021_stats.findAll('tr')[2:]

# Get stats from each row
rushing_stats2 = []
for x in range(len(rows)):
    rushing_stats2.append([col.getText() for col in rows[x].findAll('td')])
    
# Get table rows into an array
rows = rushing_2020_stats.findAll('tr')[2:]

# Get stats from each row
rushing_stats3 = []
for x in range(len(rows)):
    rushing_stats3.append([col.getText() for col in rows[x].findAll('td')])

# Check if works as desired 
# print(passing_col_headers)
print(rushing_col_headers)
print(receiving_col_headers)

for entry in rushing_stats:
  print(entry)

"""Create the dataframes 

$$ Could possibly organize into array structure
"""

# Use scraped data to create DataFrame
rushing_data = pd.DataFrame(rushing_stats, columns = rushing_col_headers[1:])
rushing_data2 = pd.DataFrame(rushing_stats2, columns = rushing_col_headers[1:])
rushing_data3 = pd.DataFrame(rushing_stats3, columns = rushing_col_headers[1:])

# Drop uneeded columns for simplicity 
rushing_data.drop(columns=["1D", "Lng"], axis=1, inplace=True)
rushing_data2.drop(columns=["1D", "Lng"], axis=1, inplace=True)
rushing_data3.drop(columns=["1D", "Lng"], axis=1, inplace=True)

# Rename cols for clarity when merging 
rushing_data = rushing_data.rename(columns={'Att':'Rush_Att', 'Yds':'Rush_Yds', 'Y/A':'Rush_Y/A', 'Y/G':'Rush_Y/G', 'TD':'Rush_TD'})
rushing_data2 = rushing_data2.rename(columns={'Att':'Rush_Att', 'Yds':'Rush_Yds', 'Y/A':'Rush_Y/A', 'Y/G':'Rush_Y/G', 'TD':'Rush_TD'})
rushing_data3 = rushing_data3.rename(columns={'Att':'Rush_Att', 'Yds':'Rush_Yds', 'Y/A':'Rush_Y/A', 'Y/G':'Rush_Y/G', 'TD':'Rush_TD'})

# Use scraped data to create DataFrame
receiving_data = pd.DataFrame(receiving_stats, columns = receiving_col_headers[1:])
receiving_data2 = pd.DataFrame(receiving_stats2, columns = receiving_col_headers[1:])
receiving_data3 = pd.DataFrame(receiving_stats3, columns = receiving_col_headers[1:])

# Drop uneeded columns for simplicity 
receiving_data.drop(columns=["1D", 'Ctch%', 'Lng'], axis=1, inplace=True)
receiving_data2.drop(columns=["1D", 'Ctch%', 'Lng'], axis=1, inplace=True)
receiving_data3.drop(columns=["1D", 'Ctch%', 'Lng'], axis=1, inplace=True)

# Rename cols for clarity when merging 
receiving_data = receiving_data.rename(columns={'Yds':'Receiving_Yds', 'Y/G':'Receiving_Y/G', 'TD':'Receiving_TD'})
receiving_data2 = receiving_data2.rename(columns={'Yds':'Receiving_Yds', 'Y/G':'Receiving_Y/G', 'TD':'Receiving_TD'})
receiving_data3 = receiving_data3.rename(columns={'Yds':'Receiving_Yds', 'Y/G':'Receiving_Y/G', 'TD':'Receiving_TD'})

# Use scraped data to create DataFrame
passing_data = pd.DataFrame(passing_stats, columns = passing_col_headers[1:])
passing_data2 = pd.DataFrame(passing_stats2, columns = passing_col_headers[1:])
passing_data3 = pd.DataFrame(passing_stats3, columns = passing_col_headers[1:])

# Rename Yds lost to Sacks column
new_cols = passing_data.columns.values
new_cols[-6] = 'Yds_Sacked'
passing_data.columns = new_cols
passing_data2.columns = new_cols
passing_data3.columns = new_cols

# Rename cols for clarity when merging 
passing_data = passing_data.rename(columns={'Yds':'Passing_Yds', 'Att':'Pass_Att', 'Y/G':'Pass_Y/G', 'TD':'Pass_TD'})
passing_data2 = passing_data2.rename(columns={'Yds':'Passing_Yds', 'Att':'Pass_Att', 'Y/G':'Pass_Y/G', 'TD':'Pass_TD'})
passing_data3 = passing_data3.rename(columns={'Yds':'Passing_Yds', 'Att':'Pass_Att', 'Y/G':'Pass_Y/G', 'TD':'Pass_TD'})

# Drop uneeded columns for simplicity 
passing_data.drop(columns=['QBrec','Yds_Sacked', 'Sk%', '4QC', 'GWD', 'NY/A', 'TD%', 'Int%', '1D', 'Y/A', 'Lng', 'QBR', 'Cmp%'], axis=1, inplace=True)
passing_data2.drop(columns=['QBrec','Yds_Sacked', 'Sk%', '4QC', 'GWD', 'NY/A', 'TD%', 'Int%', '1D', 'Y/A', 'Lng', 'QBR', 'Cmp%'], axis=1, inplace=True)
passing_data3.drop(columns=['QBrec','Yds_Sacked', 'Sk%', '4QC', 'GWD', 'NY/A', 'TD%', 'Int%', '1D', 'Y/A', 'Lng', 'QBR', 'Cmp%'], axis=1, inplace=True)

# Remove the * and + from Player names
receiving_data['Player'] = receiving_data['Player'].str.replace('*', '', regex = True)
receiving_data['Player'] = receiving_data['Player'].str.replace('+', '', regex = True)
receiving_data2['Player'] = receiving_data2['Player'].str.replace('*', '', regex = True)
receiving_data2['Player'] = receiving_data2['Player'].str.replace('+', '', regex = True)
receiving_data3['Player'] = receiving_data3['Player'].str.replace('*', '', regex = True)
receiving_data3['Player'] = receiving_data3['Player'].str.replace('+', '', regex = True)

rushing_data['Player'] = rushing_data['Player'].str.replace('*', '', regex = True)
rushing_data['Player'] = rushing_data['Player'].str.replace('+', '', regex = True)
rushing_data2['Player'] = rushing_data2['Player'].str.replace('*', '', regex = True)
rushing_data2['Player'] = rushing_data2['Player'].str.replace('+', '', regex = True)
rushing_data3['Player'] = rushing_data3['Player'].str.replace('*', '', regex = True)
rushing_data3['Player'] = rushing_data3['Player'].str.replace('+', '', regex = True)

passing_data['Player'] = passing_data['Player'].str.replace('*', '', regex = True)
passing_data['Player'] = passing_data['Player'].str.replace('+', '', regex = True)
passing_data2['Player'] = passing_data2['Player'].str.replace('*', '', regex = True)
passing_data2['Player'] = passing_data2['Player'].str.replace('+', '', regex = True)
passing_data3['Player'] = passing_data3['Player'].str.replace('*', '', regex = True)
passing_data3['Player'] = passing_data3['Player'].str.replace('+', '', regex = True)

rushing_data = rushing_data.dropna()
receiving_data = receiving_data.dropna()
passing_data = passing_data.dropna()
rushing_data2 = rushing_data2.dropna()
receiving_data2 = receiving_data2.dropna()
passing_data2 = passing_data2.dropna()
rushing_data3 = rushing_data3.dropna()
receiving_data3 = receiving_data3.dropna()
passing_data3 = passing_data3.dropna()

# Check if works 
rushing_data.head()

"""Merge our dataframes to create one overall dataframe """

WR_RB_df = pd.merge(rushing_data, receiving_data, on='Player', how='outer')
WR_RB_df2 = pd.merge(rushing_data2, receiving_data2, on='Player', how='outer')
WR_RB_df3 = pd.merge(rushing_data3, receiving_data3, on='Player', how='outer')

# Quick Check that we merged properly
WR_RB_df.head()

# 2nd merge with Passing
df = pd.merge(WR_RB_df, passing_data, on='Player', how='outer')
df2 = pd.merge(WR_RB_df2, passing_data2, on='Player', how='outer')
df3 = pd.merge(WR_RB_df3, passing_data3, on='Player', how='outer')

# Combine Position to get one column, drop others 
df['Position'] = df['Pos_x'].combine_first(df['Pos_y']).combine_first(df['Pos'])
df.drop(['Pos_x', 'Pos_y', 'Pos'], axis=1, inplace=True)
df['Team'] = df['Tm_x'].combine_first(df['Tm_y']).combine_first(df['Tm'])
df.drop(['Tm_x', 'Tm_y', 'Tm'], axis=1, inplace=True)
df['Fumbles'] = df['Fmb_x'].combine_first(df['Fmb_y'])
df.drop(['Fmb_x', 'Fmb_y'], axis=1, inplace=True)
df['Games_Played'] = df['G_x'].combine_first(df['G_y']).combine_first(df['G'])
df.drop(['G_x', 'G_y', 'G'], axis=1, inplace=True)
df['Games_Started'] = df['GS_x'].combine_first(df['GS_y']).combine_first(df['GS'])
df.drop(['GS_x', 'GS_y', 'GS'], axis=1, inplace=True)
df['Age'] = df['Age_x'].combine_first(df['Age_y'])
df.drop(['Age_x', 'Age_y'], axis=1, inplace=True)

df2['Position'] = df2['Pos_x'].combine_first(df2['Pos_y']).combine_first(df2['Pos'])
df2.drop(['Pos_x', 'Pos_y', 'Pos'], axis=1, inplace=True)
df2['Team'] = df2['Tm_x'].combine_first(df2['Tm_y']).combine_first(df2['Tm'])
df2.drop(['Tm_x', 'Tm_y', 'Tm'], axis=1, inplace=True)
df2['Fumbles'] = df2['Fmb_x'].combine_first(df2['Fmb_y'])
df2.drop(['Fmb_x', 'Fmb_y'], axis=1, inplace=True)
df2['Games_Played'] = df2['G_x'].combine_first(df2['G_y']).combine_first(df2['G'])
df2.drop(['G_x', 'G_y', 'G'], axis=1, inplace=True)
df2['Games_Started'] = df2['GS_x'].combine_first(df2['GS_y']).combine_first(df2['GS'])
df2.drop(['GS_x', 'GS_y', 'GS'], axis=1, inplace=True)
df2['Age'] = df2['Age_x'].combine_first(df2['Age_y'])
df2.drop(['Age_x', 'Age_y'], axis=1, inplace=True)

df3['Position'] = df3['Pos_x'].combine_first(df3['Pos_y']).combine_first(df3['Pos'])
df3.drop(['Pos_x', 'Pos_y', 'Pos'], axis=1, inplace=True)
df3['Team'] = df3['Tm_x'].combine_first(df3['Tm_y']).combine_first(df3['Tm'])
df3.drop(['Tm_x', 'Tm_y', 'Tm'], axis=1, inplace=True)
df3['Fumbles'] = df3['Fmb_x'].combine_first(df3['Fmb_y'])
df3.drop(['Fmb_x', 'Fmb_y'], axis=1, inplace=True)
df3['Games_Played'] = df3['G_x'].combine_first(df3['G_y']).combine_first(df3['G'])
df3.drop(['G_x', 'G_y', 'G'], axis=1, inplace=True)
df3['Games_Started'] = df3['GS_x'].combine_first(df3['GS_y']).combine_first(df3['GS'])
df3.drop(['GS_x', 'GS_y', 'GS'], axis=1, inplace=True)
df3['Age'] = df3['Age_x'].combine_first(df3['Age_y'])
df3.drop(['Age_x', 'Age_y'], axis=1, inplace=True)

# Quick Check
df.head()

"""Create categories to convert types """

categories = ['Age', 'Rush_Att', 'Rush_Yds', 'Rush_TD', 'Rush_Y/A',	'Rush_Y/G',	'Tgt',	'Rec',	'Receiving_Yds',	'Y/R',	'Receiving_TD',	'Y/Tgt',	'R/G',	'Receiving_Y/G',	'Cmp',	'Pass_Att',	'Passing_Yds',	'Pass_TD',	'Int',	'AY/A',	'Y/C',	'Pass_Y/G',	'Rate',	'Sk',	'ANY/A',	'Fumbles',	'Games_Played',	'Games_Started']

# convert data types to numeric
for x in categories:
    df[x] = pd.to_numeric(df[x])
    df2[x] = pd.to_numeric(df2[x])
    df3[x] = pd.to_numeric(df3[x])

# Fill null values with 0
df = df.fillna(0)
df2 = df2.fillna(0)
df3 = df3.fillna(0)

"""Touchdowns and Fantasy Points """

# Add up touchdowns as they are worth the same amount of points 
df['Touchdowns'] = df['Pass_TD'] + df['Rush_TD'] + df['Receiving_TD']
df2['Touchdowns'] = df2['Pass_TD'] + df2['Rush_TD'] + df2['Receiving_TD']
df3['Touchdowns'] = df3['Pass_TD'] + df3['Rush_TD'] + df3['Receiving_TD']

df['Fantasy_Points'] = (
    df['Passing_Yds'] / 25 + 
    df['Pass_TD'] * 4 +
    df['Int'] * -2 +
    df['Rush_Yds'] / 10 +
    df['Rush_TD'] * 6 +
    df['Rec'] +
    df['Receiving_Yds'] / 10 +
    df['Receiving_TD'] * 6 +
    df['Fumbles'] * -2
)

# Create Fantasy Points Column  
df['Fantasy_Points'] = (
    df['Passing_Yds'] / 25 + 
    df['Pass_TD'] * 4 +
    df['Int'] * -2 +
    df['Rush_Yds'] / 10 +
    df['Rush_TD'] * 6 +
    df['Rec'] +
    df['Receiving_Yds'] / 10 +
    df['Receiving_TD'] * 6 +
    df['Fumbles'] * -2
)
df2['Fantasy_Points'] = (
    df2['Passing_Yds'] / 25 + 
    df2['Pass_TD'] * 4 +
    df2['Int'] * -2 +
    df2['Rush_Yds'] / 10 +
    df2['Rush_TD'] * 6 +
    df2['Rec'] +
    df2['Receiving_Yds'] / 10 +
    df2['Receiving_TD'] * 6 +
    df2['Fumbles'] * -2
)
df3['Fantasy_Points'] = (
    df3['Passing_Yds'] / 25 + 
    df3['Pass_TD'] * 4 +
    df3['Int'] * -2 +
    df3['Rush_Yds'] / 10 +
    df3['Rush_TD'] * 6 +
    df3['Rec'] +
    df3['Receiving_Yds'] / 10 +
    df3['Receiving_TD'] * 6 +
    df3['Fumbles'] * -2
)

df.head()

df[df["Player"].str.strip() == "Derek Carr"]

df2[df2["Player"].str.strip() == "Tyreek Hill"]

df[df["Player"].str.strip() == "Josh Jacobs"]

"""# Linear Regression

Consider having different columns used when running LR since each position has different columns which are more important 

Some players like Deebo Samuel are used as a running back/WR hybrid
Other WRs may be more of a safety net and may get more targets but shorter routes 

RB care more about rushing yards and touches 

QBs may care more about accuracy and pass attempts 

thinking of using older seasons to train and then using newer seasons as test and compare it to projections that we can find online
"""

# Linear Regression Test
# Choose poistion we want to predict for 
choice = 'QB'
if choice == 'RB':
  X = df2[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
  y = df2['Fantasy_Points'] 
elif choice == 'WR':
  X = df2[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec', 'Fumbles']]
  y = df2['Fantasy_Points']
elif choice == 'QB':
  X = df2[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Int', 'Sk', 'Rate']]
  y = df2['Fantasy_Points']

# Split the data into training, validation, and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean squared error:", mse)
print("R-squared:", r2)

player_name = "Brian Robinson"

# Select the row corresponding to the player
player_row = df[df['Player'].str.strip() == player_name]

# Extract the predictor variables for the player
if choice == 'QB':
  player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Int', 'Sk', 'Rate']]
elif choice == 'RB':
  player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
else:
  player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec']]

# Make a prediction using the model
predicted_score = model.predict(player_data)

print(predicted_score)

"""copy baseline method from ridge

"""

# Page URL ---- RB
url = 'https://www.fantasypros.com/nfl/projections/rb.php?week=draft'

# Open and Pass url to Beautiful Soup
html = urlopen(url)
projections = BeautifulSoup(html)

# Headers
headers = projections.findAll('tr')[1]
headers = [i.getText() for i in headers.findAll('th')]

# Check out headers 
# print(headers)

# Get table rows into an array
rows = projections.findAll('tr')[1:]

# Get stats from each row
proj = []
for x in range(1,len(rows)):
    proj.append([col.getText() for col in rows[x].findAll('td')])

projections_df = pd.DataFrame(proj, columns = headers[0:])

# Keep only the player name and projections columns
projections_df = projections_df[['Player', 'FPTS']]

# Split the Player column that containes Name and Team into separate 'Player' and 'Tm' columns
projections_df[['Player', 'Tm']] = projections_df['Player'].str.extract(r'^(\S+\s+\S+)\s+(.*)$')

projections_df.drop('Tm', axis=1, inplace=True)

# Quick Check 
#projections_df.head()

#print(projections_df)

#playerlist = projections_df['Player'].values
#print(playerlist)

player_df = projections_df[['Player']].copy()
#print(player_df)

predicted_scores = []
calc_scores = []
enough = 0

for playername in player_df['Player']:

  if enough == 30:
    break
  else:
    enough+=1

  calc_scores.append(df.loc[df["Player"].str.strip() == playername, "Fantasy_Points"].values[0])

  #print(playername)
  #print(type(playername))
  #if type(playername) == float:
    #continue

  # Select the row corresponding to the player
  player_row = df[df['Player'].str.strip() == playername]

  # Extract the predictor variables for the player
  if choice == 'QB':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Int', 'Sk', 'Rate']]
  elif choice == 'RB':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
  else:
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec']]

  # Make a prediction using the model
  predicted_score = model.predict(player_data)
  predicted_scores.append(predicted_score[0])

  #print(playername + " " + str(predicted_score))

parsed_projections_df = projections_df.head(30).copy()
parsed_projections_df['FPTS'] = parsed_projections_df['FPTS'].astype(float)

parsed_projections_df['LinReg pts'] = predicted_scores
parsed_projections_df['true pts'] = calc_scores

parsed_projections_df['FPTS err'] = abs(parsed_projections_df['FPTS']-parsed_projections_df['true pts']) / parsed_projections_df['true pts']
parsed_projections_df['LinReg err'] = abs(parsed_projections_df['LinReg pts']-parsed_projections_df['true pts']) / parsed_projections_df['true pts']

print(parsed_projections_df)

avg_fpts_err = parsed_projections_df['FPTS err'].mean()
avg_linreg_err = parsed_projections_df['LinReg err'].mean()

print("fpts accuracy err = " + str(avg_fpts_err))
print("linreg accuracy err = " + str(avg_linreg_err))

"""# Ridge Regression

Logistic regression is not suitable for predicting continuous output variables like fantasy points. Logistic regression is a type of regression that is used to model binary or categorical output variables 
Was considering maybe a over/under projection 
pd.merge aint rlly working for me so maybe for the final or after talking to TA
"""

# Choose position we want to predict for 
choice = 'RB'
if choice == 'RB':
  features = ['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']
elif choice == 'WR':
  features = ['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec', 'Fumbles']
elif choice == 'QB':
  features = ['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Cmp','Int', 'Sk', 'Rate']

X = df3[features]
y = df3['Fantasy_Points']

# Split the data into training, validation, and testing sets
X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=42)

# Define the hyperparameters to be tuned
alphas = [0.01, 0.1, 1, 10, 100]

# Initialize variables to keep track of best hyperparameters and performance
best_alpha = None
best_mse = float('inf')
best_r2 = -float('inf')

# Loop over hyperparameters and fit Ridge regression models
for alpha in alphas:
    # Define the Ridge regression model
    ridge_model = Ridge(alpha=alpha)

    # Train the Ridge regression model on the training set
    ridge_model.fit(X_train, y_train)

    # Generate predictions on the validation set
    y_val_pred = ridge_model.predict(X_val)

    # Calculate the mean squared error and R-squared value on the validation set
    val_mse = mean_squared_error(y_val, y_val_pred)
    val_r2 = r2_score(y_val, y_val_pred)
    print(alpha)
    print(round(val_mse, 3))
    print(round(val_r2,5))
    # Check if the current model has better performance than previous models
    if val_mse < best_mse:
        best_alpha = alpha
        best_mse = val_mse
        best_r2 = val_r2

# Concatenate the training and validation sets for the final model
X_train_val = pd.concat([X_train, X_val], axis=0)
y_train_val = pd.concat([y_train, y_val], axis=0)

# Fit the Ridge regression model with the best hyperparameters on the combined training and validation set
ridge_model = Ridge(alpha=best_alpha)
ridge_model.fit(X_train_val, y_train_val)

# Generate predictions on the testing set
y_pred = ridge_model.predict(X_test)

# Calculate the mean squared error and R-squared value on the testing set
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

from sklearn.model_selection import GridSearchCV
# Choose position we want to predict for 
choice = 'RB'
if choice == 'RB':
  features = ['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']
elif choice == 'WR':
  features = ['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec', 'Fumbles']
elif choice == 'QB':
  features = ['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Cmp','Int', 'Sk', 'Rate']

# Extract the relevant features and target variable
X = df2[features]
y = df2['Fantasy_Points']

# Split the data into training, validation, and testing sets
X_train, X_valtest, y_train, y_valtest = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, test_size=0.5, random_state=42)

# Define the hyperparameters to be tuned
param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}

# Define the Ridge regression model
ridge_model = Ridge()

# Define the grid search object
grid_search = GridSearchCV(ridge_model, param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search object on the training set
grid_search.fit(X_train, y_train)

# Print the best hyperparameters and performance metrics
print("Best hyperparameters:", grid_search.best_params_)
print("Best negative mean squared error:", grid_search.best_score_)
print("Best R-squared value:", grid_search.best_estimator_.score(X_val, y_val))

# Generate predictions on the testing set using the best model
y_pred = grid_search.predict(X_test)

# Calculate the mean squared error and R-squared value on the testing set
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean squared error:", round(mse, 3))
print("R-squared value:", round(r2,3))

player_name = "Jonathan Taylor"

# Select the row corresponding to the player
player_row = df[df['Player'].str.strip() == player_name]

# Extract the predictor variables for the player
if choice == 'QB':
  player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Int', 'Sk', 'Rate']]
elif choice == 'RB':
  player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
elif choice =='WR':
  player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec', 'Fumbles']]

# Make a prediction using the model
predicted_score = grid_search.predict(player_data)

print(predicted_score)

df[df["Player"].str.strip() == player_name]



# Page URL ---- RB
url = 'https://www.fantasypros.com/nfl/projections/wr.php?week=draft'

# Open and Pass url to Beautiful Soup
html = urlopen(url)
projections = BeautifulSoup(html)

# Headers
headers = projections.findAll('tr')[1]
headers = [i.getText() for i in headers.findAll('th')]

# Check out headers 
headers

# Get table rows into an array
rows = projections.findAll('tr')[1:]

# Get stats from each row
proj = []
for x in range(1,len(rows)):
    proj.append([col.getText() for col in rows[x].findAll('td')])

projections_df = pd.DataFrame(proj, columns = headers[0:])

# Keep only the player name and projections columns
projections_df = projections_df[['Player', 'FPTS']]

# Split the Player column that containes Name and Team into separate 'Player' and 'Tm' columns
projections_df[['Player', 'Tm']] = projections_df['Player'].str.extract(r'^(\S+\s+\S+)\s+(.*)$')

projections_df.drop('Tm', axis=1, inplace=True)

# Quick Check 
projections_df.head()

print(projections_df)

"""create baseline measuring system

"""

# Page URL ---- RB
url = 'https://www.fantasypros.com/nfl/projections/rb.php?week=draft'

# Open and Pass url to Beautiful Soup
html = urlopen(url)
projections = BeautifulSoup(html)

# Headers
headers = projections.findAll('tr')[1]
headers = [i.getText() for i in headers.findAll('th')]

# Check out headers 
# print(headers)

# Get table rows into an array
rows = projections.findAll('tr')[1:]

# Get stats from each row
proj = []
for x in range(1,len(rows)):
    proj.append([col.getText() for col in rows[x].findAll('td')])

projections_df = pd.DataFrame(proj, columns = headers[0:])

# Keep only the player name and projections columns
projections_df = projections_df[['Player', 'FPTS']]

# Split the Player column that containes Name and Team into separate 'Player' and 'Tm' columns
projections_df[['Player', 'Tm']] = projections_df['Player'].str.extract(r'^(\S+\s+\S+)\s+(.*)$')

projections_df.drop('Tm', axis=1, inplace=True)

# Quick Check 
#projections_df.head()

#print(projections_df)

#playerlist = projections_df['Player'].values
#print(playerlist)

player_df = projections_df[['Player']].copy()
#print(player_df)

predicted_scores = []
calc_scores = []
enough = 0

for playername in player_df['Player']:

  if enough == 30:
    break
  else:
    enough+=1

  calc_scores.append(df.loc[df["Player"].str.strip() == playername, "Fantasy_Points"].values[0])

  #print(playername)
  #print(type(playername))
  #if type(playername) == float:
    #continue

  # Select the row corresponding to the player
  player_row = df[df['Player'].str.strip() == playername]

  # Extract the predictor variables for the player
  if choice == 'QB':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Int', 'Sk', 'Rate']]
  elif choice == 'RB':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
  elif choice =='WR':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec', 'Fumbles']]
  
  # Make a prediction using the model
  predicted_score = grid_search.predict(player_data)
  predicted_scores.append(predicted_score[0])

  #print(playername + " " + str(predicted_score))

parsed_projections_df = projections_df.head(30).copy()
parsed_projections_df['FPTS'] = parsed_projections_df['FPTS'].astype(float)

parsed_projections_df['RidgeReg pts'] = predicted_scores
parsed_projections_df['true pts'] = calc_scores

parsed_projections_df['FPTS err'] = abs(parsed_projections_df['FPTS']-parsed_projections_df['true pts']) / parsed_projections_df['true pts']
parsed_projections_df['RidgeReg err'] = abs(parsed_projections_df['RidgeReg pts']-parsed_projections_df['true pts']) / parsed_projections_df['true pts']

pd.set_option('display.max_rows',500)
pd.set_option('display.max_columns',504)
pd.set_option('display.width',1000)

print(parsed_projections_df)

avg_fpts_err = parsed_projections_df['FPTS err'].mean()
avg_ridgereg_err = parsed_projections_df['RidgeReg err'].mean()

print("fpts accuracy err = " + str(avg_fpts_err))
print("ridgereg accuracy err = " + str(avg_ridgereg_err))

"""now qb

"""

# Page URL ---- RB
url = 'https://www.fantasypros.com/nfl/projections/rb.php?week=draft'

# Open and Pass url to Beautiful Soup
html = urlopen(url)
projections = BeautifulSoup(html)

# Headers
headers = projections.findAll('tr')[1]
headers = [i.getText() for i in headers.findAll('th')]

# Check out headers 
# print(headers)

# Get table rows into an array
rows = projections.findAll('tr')[1:]

# Get stats from each row
proj = []
for x in range(1,len(rows)):
    proj.append([col.getText() for col in rows[x].findAll('td')])

projections_df = pd.DataFrame(proj, columns = headers[0:])

# Keep only the player name and projections columns
projections_df = projections_df[['Player', 'FPTS']]

# Split the Player column that containes Name and Team into separate 'Player' and 'Tm' columns
projections_df[['Player', 'Tm']] = projections_df['Player'].str.extract(r'^(\S+\s+\S+)\s+(.*)$')

projections_df.drop('Tm', axis=1, inplace=True)

# Quick Check 
#projections_df.head()

#print(projections_df)

#playerlist = projections_df['Player'].values
#print(playerlist)

player_df = projections_df[['Player']].copy()
#print(player_df)

predicted_scores = []
calc_scores = []
enough = 0

for playername in player_df['Player']:

  if enough == 30:
    break
  else:
    enough+=1

  calc_scores.append(df.loc[df["Player"].str.strip() == playername, "Fantasy_Points"].values[0])

  #print(playername)
  #print(type(playername))
  #if type(playername) == float:
    #continue

  # Select the row corresponding to the player
  player_row = df[df['Player'].str.strip() == playername]

  # Extract the predictor variables for the player
  if choice == 'QB':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Int', 'Sk', 'Rate']]
  elif choice == 'RB':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
  elif choice =='WR':
    player_data = player_row[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Tgt', 'Rec', 'Fumbles']]
  
  # Make a prediction using the model
  predicted_score = grid_search.predict(player_data)
  predicted_scores.append(predicted_score[0])

  #print(playername + " " + str(predicted_score))

parsed_projections_df = projections_df.head(30).copy()
parsed_projections_df['FPTS'] = parsed_projections_df['FPTS'].astype(float)

parsed_projections_df['RidgeReg pts'] = predicted_scores
parsed_projections_df['true pts'] = calc_scores

parsed_projections_df['FPTS err'] = abs(parsed_projections_df['FPTS']-parsed_projections_df['true pts']) / parsed_projections_df['true pts']
parsed_projections_df['RidgeReg err'] = abs(parsed_projections_df['RidgeReg pts']-parsed_projections_df['true pts']) / parsed_projections_df['true pts']

pd.set_option('display.max_rows',500)
pd.set_option('display.max_columns',504)
pd.set_option('display.width',1000)

print(parsed_projections_df)

avg_fpts_err = parsed_projections_df['FPTS err'].mean()
avg_ridgereg_err = parsed_projections_df['RidgeReg err'].mean()

print("fpts accuracy err = " + str(avg_fpts_err))
print("ridgereg accuracy err = " + str(avg_ridgereg_err))


# NEURAL NETWORKS
# Load data
X = df2[['Passing_Yds', 'Rush_Yds', 'Receiving_Yds', 'Pass_TD', 'Rush_TD', 'Receiving_TD', 'Age', 'Fumbles', 'Rush_Att']]
y = df2['Fantasy_Points']

# Split data into training, validation, and testing sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

# Convert data to PyTorch tensors
X_train = torch.tensor(X_train, dtype=torch.float32)
y_train = torch.tensor(y_train.values, dtype=torch.float32)
X_val = torch.tensor(X_val, dtype=torch.float32)
y_val = torch.tensor(y_val.values, dtype=torch.float32)
X_test = torch.tensor(X_test, dtype=torch.float32)
y_test = torch.tensor(y_test.values, dtype=torch.float32)

# Define dataloader objects
train_dataset = TensorDataset(X_train, y_train)
val_dataset = TensorDataset(X_val, y_val)
test_dataset = TensorDataset(X_test, y_test)
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=32)
test_dataloader = DataLoader(test_dataset, batch_size=32)

# Define neural network architecture
class TwoLayerMLP(nn.Module):
    def __init__(self, hidden_dim=200, dropout_prob=0.0):
        super(TwoLayerMLP, self).__init__()

        self.layer1 = nn.Linear(in_features=X_train.shape[1], out_features=hidden_dim)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=dropout_prob)
        self.layer2 = nn.Linear(in_features=hidden_dim, out_features=1)

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.layer2(x)
        output = x
        return output

model = TwoLayerMLP(hidden_dim=64, dropout_prob=0.1)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters())

# Train model
for epoch in range(100):
    train_loss = 0.0
    for i, (inputs, targets) in enumerate(train_dataloader):
        optimizer.zero_grad()
        outputs = model(inputs)
        targets = targets.view(-1, 1)  # reshape the target tensor
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    # Compute validation loss
    val_loss = 0.0
    with torch.no_grad():
        for inputs, targets in val_dataloader:
            outputs = model(inputs)
            targets = targets.view(-1, 1)  # reshape the target tensor
            loss = criterion(outputs, targets)
            val_loss += loss.item()

    print(f"Epoch {epoch+1} - Train Loss: {train_loss/len(train_dataloader):.4f} - Val Loss: {val_loss/len(val_dataloader):.4f}")

# Evaluate model on test set
with torch.no_grad():
    test_loss = 0.0
    for inputs, targets in test_dataloader:
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        test_loss += loss.item()

print(f'Test Loss: {test_loss/len(test_dataloader):.4f}')
